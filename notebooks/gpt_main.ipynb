{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSPNqwvUZzvQ",
        "outputId": "64bb3131-70fd-4edd-ea35-40cff7e92169"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-from-scratch'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 36 (delta 15), reused 21 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (36/36), 433.73 KiB | 4.93 MiB/s, done.\n",
            "/content/gpt-from-scratch\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/uxiost/gpt-from-scratch.git\n",
        "%cd gpt-from-scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJgAOcJ1aGQj",
        "outputId": "e95b40f4-f507-441f-847b-61b5941063e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"gpt.py\", line 189, in <module>\n",
            "    losses = estimate_loss()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"gpt.py\", line 56, in estimate_loss\n",
            "    _, loss = model(X, Y)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"gpt.py\", line 150, in forward\n",
            "    x = self.blocks(x) # (B, T, head_size=n_embd)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\", line 204, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"gpt.py\", line 129, in forward\n",
            "    x = x + self.ffwd(self.ln2(x))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"gpt.py\", line 113, in forward\n",
            "    return self.net(x)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\", line 204, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python gpt.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4 (main, Jan 18 2023, 00:26:41) [GCC 9.4.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
